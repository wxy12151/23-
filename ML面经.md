### 偏差和方差

### 过拟合和欠拟合

#### 怎么判定

#### 解决方法

### 集成模型/bagging和boosting

### 全连接层参数量计算

### 神经网络能判断自然数奇偶性吗

拥有神经网络的深度学习相比机器学习的一大特点是，深度学习的==非线性==转换能够实现一定程度上的==特征提取和特征组合==。但是，当你传入一批自然数进入模型中训练，想要预测奇偶性的时候，你会发现，这个任务有点难。但是，如果你将这些数值转为==二进制==的时候，这个任务又变得可行。可以看出，深度学习也需要我们做一下数据的==预处理==工作。当然，也侧边看出了神经网络并非万能。

### Transformer, RNN, CNN的区别

### dropout

#### 训练和测试时的区别

#### 卷积怎么Dropout

## 激活函数

### 各自优缺点

### 激活函数能全换成sigmoid吗

## 损失函数

### 了解的损失函数及它们的特点

### LR为什么用交叉熵不用MSE

## 优化器

### Adam

### Adam和SGD区别，适用场景

## 评估指标

### precision recall accuracy的区别

## LSTM

### LSTM 三个门控的作用

### LSTM和RNN的区别

## CNN

### 池化层 卷积层作用

### 降低卷积层参数量的方法

